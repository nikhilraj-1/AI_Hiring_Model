{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c1010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 5000 new rows\n",
      "üìÅ Results saved to ../results/inference_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilraj/Documents/HiringAiModel/hiring-ml-env/lib/python3.10/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/nikhilraj/Documents/HiringAiModel/hiring-ml-env/lib/python3.10/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/nikhilraj/Documents/HiringAiModel/hiring-ml-env/lib/python3.10/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/nikhilraj/Documents/HiringAiModel/hiring-ml-env/lib/python3.10/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/nikhilraj/Documents/HiringAiModel/hiring-ml-env/lib/python3.10/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/nikhilraj/Documents/HiringAiModel/hiring-ml-env/lib/python3.10/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# main.ipynb\n",
    "# Inference notebook for structured + text-based candidate-job fit\n",
    "# Choose model: uncomment XGBoost or Logistic Regression pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# --- Load New Data ---\n",
    "new_data = pd.read_csv(\"../data/ai_hiring_assignment_dataset_5000.csv\")\n",
    "print(f\"Loaded {len(new_data)} new rows\")\n",
    "\n",
    "# --- Reproduce Feature Engineering ---\n",
    "# Fill certifications\n",
    "new_data['certifications'] = new_data['certifications'].fillna(\"None\")\n",
    "\n",
    "# Skill overlap\n",
    "def compute_skill_overlap(row):\n",
    "    candidate = set(row['candidate_skills'].lower().split(','))\n",
    "    required = set(row['required_skills'].lower().split(','))\n",
    "    return len(candidate & required), len(required), len(candidate)\n",
    "\n",
    "new_data[['skill_overlap', 'required_skill_count', 'candidate_skill_count']] = new_data.apply(\n",
    "    lambda row: pd.Series(compute_skill_overlap(row)), axis=1\n",
    ")\n",
    "new_data['skill_match_ratio'] = new_data['skill_overlap'] / new_data['required_skill_count']\n",
    "\n",
    "# Salary mismatch\n",
    "avg_budgeted_salary = (new_data['budgeted_salary_min'] + new_data['budgeted_salary_max']) / 2\n",
    "new_data['salary_diff'] = new_data['expected_salary'] - avg_budgeted_salary\n",
    "\n",
    "# Experience gap\n",
    "new_data['experience_gap'] = new_data['years_experience'] - new_data['min_experience']\n",
    "\n",
    "# Text lengths\n",
    "new_data['job_desc_len'] = new_data['job_description'].str.len()\n",
    "new_data['past_titles_len'] = new_data['past_job_titles'].str.len()\n",
    "\n",
    "# Label Encoding for categorical features\n",
    "label_cols = ['education_level', 'candidate_location', 'job_location']\n",
    "for col in label_cols:\n",
    "    le = joblib.load(f\"../models/{col}_label_encoder.pkl\")\n",
    "    new_data[col] = le.transform(new_data[col])\n",
    "\n",
    "# Combine text columns\n",
    "text_cols = ['candidate_skills', 'past_job_titles', 'certifications', 'required_skills', 'job_description']\n",
    "def combine_text(df):\n",
    "    return df[text_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
    "new_data[\"combined_text\"] = combine_text(new_data)\n",
    "\n",
    "# --- Final Inference Features ---\n",
    "feature_cols = [\n",
    "    'years_experience', 'expected_salary', 'min_experience',\n",
    "    'budgeted_salary_min', 'budgeted_salary_max',\n",
    "    'education_level', 'candidate_location', 'job_location', 'job_title',\n",
    "    'candidate_skills', 'past_job_titles', 'certifications',\n",
    "    'required_skills', 'job_description',\n",
    "    'skill_overlap', 'required_skill_count', 'candidate_skill_count',\n",
    "    'skill_match_ratio', 'salary_diff', 'experience_gap',\n",
    "    'job_desc_len', 'past_titles_len', 'combined_text'\n",
    "]\n",
    "X_new = new_data[feature_cols]\n",
    "\n",
    "# -------------------------\n",
    "# Load ONE model below\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "model = joblib.load(\"../models/xgb_pipeline.joblib\")\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_new)\n",
    "y_proba = model.predict_proba(X_new)[:, 1]\n",
    "\n",
    "\n",
    "new_data[\"fit_prediction\"] = y_pred\n",
    "new_data[\"fit_probability\"] = y_proba\n",
    "new_data.to_csv(\"../inference_results.csv\", index=False)\n",
    "print(\"Results saved to ../results/inference_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiring-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
